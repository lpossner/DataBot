{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea91d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b634b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "DB_PATH = \"Data/dummy_data.db\"\n",
    "\n",
    "# Load dataset with igef (vehicle), test name, and test_result (OK/NOK)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df = pd.read_sql(\"SELECT * FROM dummy_data\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c815af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target test and split ratio\n",
    "label = \"test_80\"\n",
    "test_size = 0.2\n",
    "\n",
    "# Convert test_result to binary (OK=0, NOK=1)\n",
    "df[\"binary_test_result\"] = df[\"test_result\"].map({\"OK\": 0, \"NOK\": 1})\n",
    "\n",
    "# Create target labels: one result per vehicle for test_80 (NOK overrides OK)\n",
    "y = (\n",
    "    df[df[\"test\"] == label]\n",
    "    .groupby(\"igef\")[\"binary_test_result\"]\n",
    "    .max()\n",
    "    .rename(label)\n",
    "    .to_frame()\n",
    ")\n",
    "\n",
    "# Create feature matrix: one row per vehicle, one column per test (excluding test_80)\n",
    "X = (\n",
    "    df[df[\"test\"] != label]\n",
    "    .pivot_table(index=\"igef\", columns=\"test\", values=\"binary_test_result\", aggfunc=\"max\")\n",
    "    .sort_index(axis=1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Merge features with target labels\n",
    "data = X.join(y, how=\"inner\").reset_index()\n",
    "\n",
    "# Split by vehicle, stratified to preserve OK/NOK ratio and avoid leakage\n",
    "igefs = data[\"igef\"].unique()\n",
    "igef_train, igef_test = train_test_split(\n",
    "    igefs,\n",
    "    test_size=test_size,\n",
    "    stratify=data[label],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train = data[data[\"igef\"].isin(igef_train)]\n",
    "test = data[data[\"igef\"].isin(igef_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d8b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251030_104950\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:34 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.38 GB / 16.00 GB (33.6%)\n",
      "Disk Space Avail:   65.11 GB / 228.27 GB (28.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/Users/lpossner/Projects/databot/AutogluonModels/ag-20251030_104950\"\n",
      "Train Data Rows:    800\n",
      "Train Data Columns: 80\n",
      "Label Column:       test_80\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5502.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 80 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 80 | ['test_0', 'test_1', 'test_10', 'test_11', 'test_12', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 80 | ['test_0', 'test_1', 'test_10', 'test_11', 'test_12', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.51s of the 1799.72s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\t0.0\t = Validation score   (f1)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1194.19s of the 1794.40s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\t0.0\t = Validation score   (f1)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1191.32s of the 1791.53s of remaining time.\n",
      "\t0.9231\t = Validation score   (f1)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1190.74s of the 1790.94s of remaining time.\n",
      "\t0.963\t = Validation score   (f1)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1190.43s of the 1790.64s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=8.23%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t6.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1182.57s of the 1782.78s of remaining time.\n",
      "\t0.963\t = Validation score   (f1)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1182.21s of the 1782.42s of remaining time.\n",
      "\t0.9756\t = Validation score   (f1)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1181.91s of the 1782.12s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1178.07s of the 1778.27s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\t0.6452\t = Validation score   (f1)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1175.07s of the 1775.28s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.5263\t = Validation score   (f1)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1169.90s of the 1770.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.50%)\n",
      "\t0.9756\t = Validation score   (f1)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1767.15s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1766.99s of the 1766.99s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1764.51s of the 1764.50s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1761.92s of the 1761.91s of remaining time.\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1761.45s of the 1761.44s of remaining time.\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1761.15s of the 1761.14s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=8.19%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t13.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1745.79s of the 1745.78s of remaining time.\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1745.45s of the 1745.44s of remaining time.\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1745.15s of the 1745.14s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t2.31s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1741.38s of the 1741.37s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.85%)\n",
      "\t0.988\t = Validation score   (f1)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1738.71s of the 1738.71s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t2.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1734.11s of the 1734.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.67%)\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1731.27s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 1.0}\n",
      "\t1.0\t = Validation score   (f1)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 68.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 23310.9 rows/s (160 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 1.0000\n",
      "\tBest Threshold: 0.500\t| val: 1.0000\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/lpossner/Projects/databot/AutogluonModels/ag-20251030_104950\")\n"
     ]
    }
   ],
   "source": [
    "# Train AutoGluon TabularPredictor\n",
    "# label: column to predict (\"test_80\")\n",
    "# eval_metric: F1 (robust to class imbalance)\n",
    "# train_data: drop vehicle ID (\"igef\")\n",
    "# presets: balanced speed/quality config\n",
    "# num_bag_folds: bagging via cross-validation for generalization\n",
    "# num_stack_levels: model stacking for extra accuracy\n",
    "# time_limit: max 1800 s (~30 min)\n",
    "predictor = (\n",
    "    TabularPredictor(label=label, eval_metric=\"f1\")\n",
    "    .fit(\n",
    "        train_data=train.drop(columns=[\"igef\"]),\n",
    "        presets=\"medium_quality_faster_train\",\n",
    "        num_bag_folds=5,\n",
    "        num_stack_levels=1,\n",
    "        time_limit=1800\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8751dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 80 features using 200 rows with 5 shuffle sets...\n",
      "\t6.79s\t= Expected runtime (1.36s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model  score_test  score_val eval_metric  \\\n",
      "0           CatBoost_BAG_L1    1.000000   1.000000          f1   \n",
      "1       WeightedEnsemble_L2    1.000000   1.000000          f1   \n",
      "2    NeuralNetFastAI_BAG_L1    1.000000   1.000000          f1   \n",
      "3      LightGBMLarge_BAG_L2    1.000000   1.000000          f1   \n",
      "4           LightGBM_BAG_L2    1.000000   1.000000          f1   \n",
      "5           CatBoost_BAG_L2    1.000000   1.000000          f1   \n",
      "6            XGBoost_BAG_L2    1.000000   0.987952          f1   \n",
      "7     NeuralNetTorch_BAG_L2    1.000000   1.000000          f1   \n",
      "8    NeuralNetFastAI_BAG_L2    1.000000   1.000000          f1   \n",
      "9     ExtraTreesGini_BAG_L2    1.000000   1.000000          f1   \n",
      "10      WeightedEnsemble_L3    1.000000   1.000000          f1   \n",
      "11  RandomForestEntr_BAG_L2    1.000000   1.000000          f1   \n",
      "12  RandomForestGini_BAG_L2    1.000000   1.000000          f1   \n",
      "13    ExtraTreesEntr_BAG_L2    1.000000   1.000000          f1   \n",
      "14     LightGBMLarge_BAG_L1    0.750000   0.975610          f1   \n",
      "15  RandomForestEntr_BAG_L1    0.750000   0.962963          f1   \n",
      "16  RandomForestGini_BAG_L1    0.750000   0.923077          f1   \n",
      "17    ExtraTreesEntr_BAG_L1    0.750000   0.975610          f1   \n",
      "18    ExtraTreesGini_BAG_L1    0.750000   0.962963          f1   \n",
      "19        LightGBMXT_BAG_L2    0.750000   1.000000          f1   \n",
      "20           XGBoost_BAG_L1    0.461538   0.645161          f1   \n",
      "21    NeuralNetTorch_BAG_L1    0.181818   0.526316          f1   \n",
      "22          LightGBM_BAG_L1    0.000000   0.000000          f1   \n",
      "23        LightGBMXT_BAG_L1    0.000000   0.000000          f1   \n",
      "\n",
      "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
      "0         0.067352       0.006633   6.459332                 0.067352   \n",
      "1         0.068210       0.007788   6.610949                 0.000858   \n",
      "2         0.247296       0.019486   2.348182                 0.247296   \n",
      "3         0.417350       0.153690  15.736304                 0.003707   \n",
      "4         0.417375       0.154060  15.843514                 0.003732   \n",
      "5         0.427897       0.160328  28.779112                 0.014254   \n",
      "6         0.429577       0.157888  15.642167                 0.015934   \n",
      "7         0.432810       0.175465  17.840209                 0.019167   \n",
      "8         0.440523       0.170944  17.214342                 0.026880   \n",
      "9         0.443543       0.196364  15.180790                 0.029901   \n",
      "10        0.444137       0.199775  15.319818                 0.000594   \n",
      "11        0.444772       0.194924  15.137406                 0.031129   \n",
      "12        0.444874       0.196621  15.311136                 0.031231   \n",
      "13        0.445748       0.196016  15.139908                 0.032105   \n",
      "14        0.009468       0.007722   0.998324                 0.009468   \n",
      "15        0.019330       0.047683   0.240445                 0.019330   \n",
      "16        0.030101       0.048998   0.474340                 0.030101   \n",
      "17        0.031085       0.048234   0.241052                 0.031085   \n",
      "18        0.032024       0.047031   0.295934                 0.032024   \n",
      "19        0.418386       0.155570  15.748222                 0.004743   \n",
      "20        0.026658       0.008574   0.995082                 0.026658   \n",
      "21        0.012454       0.010956   3.619520                 0.012454   \n",
      "22        0.003413       0.002583   0.928133                 0.003413   \n",
      "23        0.214047       0.002684   0.600457                 0.214047   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.006633           6.459332            1       True   \n",
      "1                 0.001156           0.151617            2       True   \n",
      "2                 0.019486           2.348182            1       True   \n",
      "3                 0.004403           0.834367            2       True   \n",
      "4                 0.004773           0.941577            2       True   \n",
      "5                 0.011041          13.877175            2       True   \n",
      "6                 0.008601           0.740230            2       True   \n",
      "7                 0.026178           2.938272            2       True   \n",
      "8                 0.021657           2.312405            2       True   \n",
      "9                 0.047077           0.278853            2       True   \n",
      "10                0.003410           0.139028            3       True   \n",
      "11                0.045637           0.235469            2       True   \n",
      "12                0.047334           0.409199            2       True   \n",
      "13                0.046728           0.237971            2       True   \n",
      "14                0.007722           0.998324            1       True   \n",
      "15                0.047683           0.240445            1       True   \n",
      "16                0.048998           0.474340            1       True   \n",
      "17                0.048234           0.241052            1       True   \n",
      "18                0.047031           0.295934            1       True   \n",
      "19                0.006283           0.846285            2       True   \n",
      "20                0.008574           0.995082            1       True   \n",
      "21                0.010956           3.619520            1       True   \n",
      "22                0.002583           0.928133            1       True   \n",
      "23                0.002684           0.600457            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0           5  \n",
      "1          12  \n",
      "2           8  \n",
      "3          23  \n",
      "4          14  \n",
      "5          17  \n",
      "6          21  \n",
      "7          22  \n",
      "8          20  \n",
      "9          18  \n",
      "10         24  \n",
      "11         16  \n",
      "12         15  \n",
      "13         19  \n",
      "14         11  \n",
      "15          4  \n",
      "16          3  \n",
      "17          7  \n",
      "18          6  \n",
      "19         13  \n",
      "20          9  \n",
      "21         10  \n",
      "22          2  \n",
      "23          1  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       190\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "[[190   0]\n",
      " [  0  10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         importance    stddev   p_value  n  p99_high   p99_low\n",
      "test_2     0.360000  0.036515  0.000013  5  0.435185  0.284815\n",
      "test_1     0.283072  0.091498  0.001146  5  0.471467  0.094677\n",
      "test_4     0.214436  0.035653  0.000088  5  0.287846  0.141026\n",
      "test_3     0.098195  0.045124  0.004122  5  0.191107  0.005284\n",
      "test_61    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_60    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_6     0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_59    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_58    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_57    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_56    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_0     0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_55    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_62    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_53    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_52    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_51    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_50    0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_5     0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
      "test_49    0.000000  0.000000  0.500000  5  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "\n",
    "# Show leaderboard with model performance and training stats\n",
    "leaderboard = predictor.leaderboard(test.drop(columns=[\"igef\"]), silent=True)\n",
    "print(leaderboard)\n",
    "\n",
    "# Predict test labels (drop igef)\n",
    "y_true = test[label]\n",
    "y_pred = predictor.predict(test.drop(columns=[\"igef\"]))\n",
    "\n",
    "# Print precision, recall, and F1-score\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Show confusion matrix (true vs. predicted)\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Display top feature importances\n",
    "features_importances = predictor.feature_importance(test.drop(columns=[\"igef\"]))\n",
    "print(features_importances.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
