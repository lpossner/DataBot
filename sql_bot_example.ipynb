{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a66afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Annotated, List, TypedDict, Optional, Any, Dict\n",
    "import sqlite3, textwrap\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81528e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "DB_PATH = \"Data/dummy_data.db\"\n",
    "\n",
    "# Set up local LLM usimg Llama Cpp\n",
    "chat = ChatLlamaCpp(\n",
    "    model_path=\"./LlamaCppModels/Llama-3.2-1B-Instruct/Llama-3.2-1B-Instruct-Q6_K_L.gguf\",\n",
    "    n_ctx=4096,\n",
    "    n_threads=8,\n",
    "    temperature=0.4,\n",
    "    model_kwargs={\"chat_format\": \"llama-3\"},\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1cb3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State carries the running chat, the planned SQL, any fetched rows, and potential errors.\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], \"Running chat transcript\"]\n",
    "    sql: Optional[str]\n",
    "    rows: Optional[List[Dict[str, Any]]]\n",
    "    error: Optional[str]\n",
    "\n",
    "# The schema inspector produces a compact, LLM-friendly description of tables, columns, and foreign keys.\n",
    "def inspect_schema(db_path: str) -> str:\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.row_factory = sqlite3.Row\n",
    "    cur = con.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' \"\n",
    "        \"AND name NOT LIKE 'sqlite_%' ORDER BY name;\"\n",
    "    )\n",
    "    tables = [r[\"name\"] for r in cur.fetchall()]\n",
    "\n",
    "    parts: List[str] = []\n",
    "    for t in tables:\n",
    "        cur.execute(f\"PRAGMA table_info({t});\")\n",
    "        cols = cur.fetchall()\n",
    "        cols_desc = \", \".join(f\"{c['name']} {c['type']}\" for c in cols)\n",
    "        parts.append(f\"- {t}({cols_desc})\")\n",
    "\n",
    "        cur.execute(f\"PRAGMA foreign_key_list({t});\")\n",
    "        fks = cur.fetchall()\n",
    "        for fk in fks:\n",
    "            parts.append(f\"    ↳ FK {fk['from']} → {fk['table']}({fk['to']})\")\n",
    "\n",
    "    con.close()\n",
    "    if not parts:\n",
    "        return \"(No user tables found.)\"\n",
    "    return \"Tables:\\n\" + \"\\n\".join(parts)\n",
    "\n",
    "# The guardrail only allows SELECT or WITH…SELECT and appends a LIMIT when missing.\n",
    "def ensure_readonly_select(sql: str, default_limit: int = 50) -> str:\n",
    "    s = sql.strip().rstrip(\";\")\n",
    "    lowered = s.lower()\n",
    "    if not (lowered.startswith(\"select\") or lowered.startswith(\"with \")):\n",
    "        raise ValueError(\"Only read-only SELECT queries are allowed.\")\n",
    "    if \" limit \" not in lowered:\n",
    "        s += f\" LIMIT {default_limit}\"\n",
    "    return s + \";\"\n",
    "\n",
    "# The executor runs the safe query and returns rows as dictionaries.\n",
    "def run_select(db_path: str, sql: str) -> List[Dict[str, Any]]:\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.row_factory = sqlite3.Row\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    rows = [dict(r) for r in cur.fetchall()]\n",
    "    con.close()\n",
    "    return rows\n",
    "\n",
    "# The planner system prompt asks for a single SQL statement with strict read-only constraints.\n",
    "SYS_PLANNER = SystemMessage(content=textwrap.dedent(\"\"\"\\\n",
    "You are a careful SQL planning assistant for a SQLite database.\n",
    "Produce exactly one SQL statement that answers the user question using only SELECT or WITH…SELECT.\n",
    "Use table and column names exactly as given by the schema.\n",
    "Apply a reasonable LIMIT when the question does not require full detail.\n",
    "Do not include explanations or any text besides the SQL itself.\n",
    "\"\"\"))\n",
    "\n",
    "# Optional static schema hint. Replace with inspect_schema(DB_PATH) if you want live inspection.\n",
    "SCHEMA = \"\"\"\\\n",
    "Tables:\n",
    "- dummy_data(igef TEXT, test TEXT, test_result TEXT)\n",
    "\n",
    "Available values in columns:\n",
    "- test_result: OK, NOK\n",
    "\"\"\"\n",
    "\n",
    "# The planner asks the model for a single SQL statement and stores it in state.\n",
    "def plan_sql(state: ChatState) -> ChatState:\n",
    "    schema = SCHEMA  # or: inspect_schema(DB_PATH)\n",
    "    user_msg = next((m for m in reversed(state[\"messages\"]) if isinstance(m, HumanMessage)), None)\n",
    "    question = user_msg.content if user_msg else \"Show something useful from the database.\"\n",
    "\n",
    "    plan_prompt = (\n",
    "        f\"Database schema:\\n{schema}\\n\\n\"\n",
    "        f\"User question:\\n{question}\\n\\n\"\n",
    "        f\"Return only the SQL statement.\"\n",
    "    )\n",
    "\n",
    "    resp = chat.invoke([SYS_PLANNER, HumanMessage(content=plan_prompt)])\n",
    "    sql = (resp.content or \"\").strip()\n",
    "    return {**state, \"sql\": sql, \"error\": None}\n",
    "\n",
    "# The executor applies the read-only guardrail and runs the query against SQLite.\n",
    "def execute_sql(state: ChatState) -> ChatState:\n",
    "    if state.get(\"error\"):\n",
    "        return state\n",
    "    try:\n",
    "        safe_sql = ensure_readonly_select(state[\"sql\"] or \"\")\n",
    "        rows = run_select(DB_PATH, safe_sql)\n",
    "        return {**state, \"sql\": safe_sql, \"rows\": rows, \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {**state, \"rows\": None, \"error\": f\"SQL execution error: {e}\"}\n",
    "\n",
    "# The responder prints the exact SQL and a compact preview of the first few rows.\n",
    "def respond(state: ChatState) -> ChatState:\n",
    "    if state.get(\"error\"):\n",
    "        msg = f\"⚠️ {state['error']}\"\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=msg)],\n",
    "            \"sql\": None,\n",
    "            \"rows\": None,\n",
    "            \"error\": state[\"error\"],\n",
    "        }\n",
    "\n",
    "    rows = state.get(\"rows\") or []\n",
    "    sql = state.get(\"sql\") or \"\"\n",
    "    preview = rows[:10]\n",
    "\n",
    "    if preview:\n",
    "        headers = list(preview[0].keys())\n",
    "        lines = [\" | \".join(headers), \" | \".join([\"---\"] * len(headers))]\n",
    "        for r in preview:\n",
    "            lines.append(\" | \".join(str(r.get(h, \"\")) for h in headers))\n",
    "        table_md = \"\\n\".join(lines)\n",
    "    else:\n",
    "        table_md = \"_No rows returned._\"\n",
    "\n",
    "    answer = (\n",
    "        f\"**SQL**\\n\"\n",
    "        f\"```sql\\n{sql}\\n```\\n\\n\"\n",
    "        f\"**Preview ({len(preview)} of {len(rows)} rows)**\\n\"\n",
    "        f\"{table_md}\"\n",
    "    )\n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=answer)], \"sql\": sql, \"rows\": rows, \"error\": None}\n",
    "\n",
    "# The graph wires the three nodes into a single planning-execution-response pass.\n",
    "builder = StateGraph(ChatState)\n",
    "builder.add_node(\"plan_sql\", plan_sql)\n",
    "builder.add_node(\"execute_sql\", execute_sql)\n",
    "builder.add_node(\"respond\", respond)\n",
    "\n",
    "builder.add_edge(START, \"plan_sql\")\n",
    "builder.add_edge(\"plan_sql\", \"execute_sql\")\n",
    "builder.add_edge(\"execute_sql\", \"respond\")\n",
    "builder.add_edge(\"respond\", END)\n",
    "\n",
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d32c9375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**SQL**\n",
      "```sql\n",
      "SELECT dummy_data.igef FROM dummy_data WHERE test_result = 'NOK' LIMIT 5;\n",
      "```\n",
      "\n",
      "**Preview (5 of 5 rows)**\n",
      "igef\n",
      "---\n",
      "igef_186\n",
      "igef_479\n",
      "igef_133\n",
      "igef_869\n",
      "igef_2\n"
     ]
    }
   ],
   "source": [
    "initial = ChatState(messages=[HumanMessage(content=\"Show the 5 IGEFs where the most tests failed.\")],\n",
    "                    sql=None, sql_explanation=None, rows=None, error=None)\n",
    "result = app.invoke(initial)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
